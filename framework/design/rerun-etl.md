# 重跑 etl

- [设计图](https://www.processon.com/view/link/55e5630ee4b02026c208a46b)
- [依赖处理流程图](https://www.processon.com/view/link/55e666b1e4b02026c20f2d83)

```
方案一
  层级思路:
    1.找到没有依赖的 Job ,作为 level_1
    2.找到依赖 level_1 的 Job ,作为 level_2
    3.找到依赖 level_2 的 Job ,作为 level_3
    4.以此类推

  问题：
    1.目前 job 不是按照层级依赖，会有多层依赖，比如 level_3 可能是 DA 的数据，但是 DA 可能会依赖宽表 level_2，也可能会依赖基础 etl level_1
    2.比如，宽表和宽表也会互相依赖

  解决:
    需要调整，宽表依赖层级，严格按照层级制度处理依赖，比如
    level_1 不允许有依赖
    level_2 只能依赖 level_1
    level_3 只能依赖 level_2


方案二
  通过递归方式:
    设计图：https://www.processon.com/view/link/55e666b1e4b02026c20f2d83

  问题：
    实现麻烦，繁琐


方案三
  使用 scheduler 本事依赖机制:
    一次提交，所有有效的 jobs 给调度系统，调度系统会按照运行本身的依赖机制，去处理依赖运行问题

  问题：
    1. 只有自动执行的 Job 才会
    2. 需要新增一个功能，启动主 Job 后，按照依赖关系图，自定运行 Job
```


## 一、设计目的

- 一天多次执行
- 可以一天提供多次数据


## 二、影响部分

### 1.涉及脚本类型

- 基础 etl shell
- 使用 /home/dwadmin/dwetl/dw_general_loader.jar 包，调用的项目开发
  - 包括 hive 存储过程
  - 数据抽取

### 2.涉及到的业务表

- 三大主题宽表，以及生成主题宽表所依赖的数据
- da 层数据
- art 数据表
- minireport 数据


## 三、实现步骤

分析下来

基础的 etl + 业务宽表 + art ，总计需要 2 个小时基本可以全部跑完

我们有 2 个时间段需要数据


- 00:01 - 12:00
  - 基础的 etl
  - 主题宽表
  - 提供给 DA
  - 提供 ART
  - 提供给 minireport
- 12:01 - 19:00
 - 基础的 etl
 - 主题宽表
 - 提供给 DA。(这里不需要，因为业务每天拉一次数据)


### 方法 1

调整调度系统

```
1. uba-run 每天 00:00:01 / 00:12:01 运行一次

2. m2h-sync-dump-run 每天 00:00:01 / 00:12:01 运行一次
  01 00 00,12 * * ? *

3. 三大主题宽表
  设计好依赖，按照上述方法，每天运行 2 次

```

### 方法 2

使用脚本处理

```
如 二、1 所示

通过一个入口 shell 文件，按照依赖关系图
  https://www.processon.com/view/link/55d6d002e4b0b896159963f7
根据主题去数据库获取有效的脚本依次执行

```
